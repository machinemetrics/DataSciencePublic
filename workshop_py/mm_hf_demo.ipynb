{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo Python/Jupyter analysis of MachineMetrics high-frequency predictive data\n",
    "This customer is manufacturing automotive parts on a mill. In the time period covered by our example data set, the customer reported that 17 parts had to be scrapped due to a tool going bad without the operator having noticed. Besides the lost material, that led to about half an hour of wasted machine time. \n",
    "\n",
    "\n",
    "### *Could we have spotted this problem earlier using high-frequency data monitoring?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Download and unzip the data set, if you don't already have it!\n",
    "* Only run this cell if you didn't already download/unzip.\n",
    "* Place the unzipped CSVs into the same folder as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from zipfile import ZipFile\n",
    "print(\"Downloading from S3...\")\n",
    "zipname = 'hf_python_files.zip'\n",
    "zipresp = urlopen(f'https://machinemetrics-public.s3-us-west-2.amazonaws.com/ds/{zipname}')\n",
    "with open(zipname, 'wb') as zipfile:\n",
    "    zipfile.write(zipresp.read())\n",
    "print(\"Unzipping...\")\n",
    "with ZipFile(zipname) as zipfile:\n",
    "    zipfile.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import packages, customize plot settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display, clear_output\n",
    "from time import time, sleep\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "matplotlib.rcParams['figure.dpi'] = 100\n",
    "matplotlib.rcParams['axes.titlesize'] = 20\n",
    "matplotlib.rcParams['axes.titleweight'] = 'bold'\n",
    "matplotlib.rcParams['axes.labelsize'] = 16\n",
    "matplotlib.rcParams['legend.fontsize'] = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load the data set\n",
    "* Consists of a dense high-frequency (kHz) set and a sparse set consisting of cleaned-up partcount and tool use period boundaries.\n",
    "* Each covers a ~3h45m period.\n",
    "* 132 parts, typical cycle time ~90s, 3 distinct tool use periods per part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hf = pd.read_csv('hf2.csv', parse_dates=True, index_col='timestamp')\n",
    "df_pt = pd.read_csv('partsTools.csv', parse_dates=True, index_col='timestamp')\n",
    "\n",
    "print(\"Raw kHz high-frequency data set:\")\n",
    "display(df_hf)\n",
    "print(\"Precleaned partcount/tool boundaries data set:\")\n",
    "display(df_pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data grooming:\n",
    "* Simplify column names\n",
    "* Cut out low-activity periods (pauses between part cycles, dowtime, etc)\n",
    "* Use the partcount and tool dataframe as a lookup table for *rapidly* slicing the HF dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hf = (\n",
    "    df_hf\n",
    "    .rename(columns={'SPINDLE_1_load':'load', 'SPINDLE_1_motor_speed':'speed'})\n",
    "    .query('load > 2 or abs(speed) > 2')\n",
    ")\n",
    "print(\"The groomed kHz time series:\")\n",
    "display(df_hf)\n",
    "\n",
    "df_pt = (\n",
    "    df_pt\n",
    "    .reset_index()\n",
    "    .set_index(['partcount', 'T'])\n",
    ")\n",
    "all_parts_tools = df_pt.index[:-3]  # the last few steps over-run the kHz data\n",
    "print(\"The lookup table for parts and tools:\")\n",
    "display(df_pt)\n",
    "\n",
    "def get_part_tool(partcount, T):\n",
    "    \"\"\"\n",
    "    Get a specific partcount & tool use period from the HF time series using efficient Pandas time slicing\n",
    "    \"\"\"\n",
    "    if (partcount, T) not in df_pt.index:\n",
    "        return None\n",
    "    start_timestamp = df_pt.at[(partcount, T), 'timestamp']\n",
    "    end_timestamp =  df_pt.shift(-1).at[(partcount, T), 'timestamp']\n",
    "    return df_hf.loc[start_timestamp:end_timestamp] if pd.notna(end_timestamp) else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "## 4. Test: Grab a specific (partcount, tool) period using the lookup table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(df_pt.loc[(45,1)]['timestamp'], 'thru', df_pt.loc[(45,2)]['timestamp'])\n",
    "dft = get_part_tool(45, 1)\n",
    "display(dft)\n",
    "dft['load'].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. First exploratory: What do the raw signals look like before/during the fault?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tools = all_parts_tools.get_level_values(1).unique()\n",
    "\n",
    "def plot_parts(partcounts, metric, tools=all_tools, **plt_kwargs):\n",
    "    \"\"\"\n",
    "    Custom plotting function for a given list of parts and a given HF metric\n",
    "    Constructs one plot per tool use period, and overlays multiple parts on each plot\n",
    "    \"\"\"\n",
    "    partcounts = partcounts if hasattr(partcounts, '__iter__') else [partcounts]\n",
    "    fig, axs = plt.subplots(1, len(tools), figsize=(24, 5))\n",
    "    axs[0].set_ylabel(metric, fontsize=20)\n",
    "    for T, ax in zip(tools, axs):\n",
    "        for partcount in partcounts:\n",
    "            label = f'part {partcount}'\n",
    "            if (partcount, T) in all_parts_tools:\n",
    "                get_part_tool(partcount, T)[metric].plot(label=label, ax=ax, use_index=False, **plt_kwargs)\n",
    "            else:\n",
    "                ax.plot([], [], label=label)\n",
    "        ax.set_title(f'T = {T}')\n",
    "        ax.set_xlabel(f'milliseconds')\n",
    "        plt.gca().relim()\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "test_parts = [0, 1, 121, 122]\n",
    "plot_parts(test_parts, 'load')\n",
    "plot_parts(test_parts, 'speed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Any clues in simple integrated time series features? First, build some and put them into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_rows = []\n",
    "previous_partcount = 0\n",
    "for partcount, T in all_parts_tools:\n",
    "    if partcount != previous_partcount:\n",
    "        print(partcount, end=' ')\n",
    "        previous_partcount = partcount\n",
    "    dft = get_part_tool(partcount, T)\n",
    "    feature_rows.append({\n",
    "        'duration':len(dft),\n",
    "        'load_integral':dft['load'].sum(),\n",
    "        })\n",
    "print()\n",
    "df_features = pd.DataFrame(index=all_parts_tools, data=feature_rows)\n",
    "display(df_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Plot some (normalized) features for our sample of parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fault_part = 122\n",
    "def plot_feature(feature, tools=all_tools, **plt_kwargs):\n",
    "    \"\"\"\n",
    "    Plot a derived time series feature versus partcount\n",
    "    Each tool use period is overlayed as a separate line\n",
    "    Features are automatically normalized to the median per-tool\n",
    "    \"\"\"\n",
    "    dft = df_features.swaplevel()\n",
    "    fig, ax = plt.subplots(figsize=(24, 5))\n",
    "    for T in tools:\n",
    "        (dft.loc[T, feature] / dft.loc[T, feature].median()).plot(ax=ax, label=f'tool {T}', **plt_kwargs)\n",
    "        ax.set_xlabel(f'partcount')\n",
    "        ax.set_ylabel('value / (tool median)', fontsize=20)\n",
    "    ax.set_title(feature)\n",
    "    plt.gca().relim()\n",
    "    plt.legend()\n",
    "    plt.axvline(fault_part, color='red', linewidth=3)\n",
    "    plt.show()\n",
    "\n",
    "#plot_feature('duration', tools=[1, 2, 3], ylim=[0.98, 1.02])\n",
    "plot_feature('load_integral', tools=[1, 2, 3], ylim=[0.95, 1.05])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Let's dive a bit deeper: Instead of looking at the overall intensity of machining, we can look at its overall *stability*\n",
    "* Do this by looking at the \"noise\" on top of the signals, in both time-domain and frequency-domain (Fourier transform).\n",
    "* To get a clear noise signal, we will first de-trend the data at the 100-millisecond scale. (Subtract a smoothed-out signal.)\n",
    "* Spindle speed requires simpler processing than spindle load since it's mostly flat, so let's focus on that metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothing_window = 101\n",
    "\n",
    "test_part, test_tool = 100, 1\n",
    "tmin, tmax = 1000, 5000\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(24, 5))\n",
    "speed = get_part_tool(test_part, test_tool)['speed'].iloc[tmin:tmax]\n",
    "speed_smoothed = speed.rolling(smoothing_window, center=True).mean()\n",
    "speed.plot(use_index=False, label='original signal')\n",
    "speed_smoothed.plot(use_index=False, linewidth=4, label='smoothed signal')\n",
    "plt.xlabel('milliseconds')\n",
    "plt.ylabel('Speed (RPM)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Scanning the time and frequency signals near the fault reveals something interesting\n",
    "* The tool that failed is mostly operating at 2100 RPM, which corresponds to 35 Hz. That should be an interesting place to monitor for anomalies in frequency space.\n",
    "* Pay attention to when part #106 comes up!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import periodogram\n",
    "\n",
    "smoothing_window = 101\n",
    "\n",
    "test_parts, test_tool = range(95, 122+1), 1\n",
    "\n",
    "xlim_time = 0, 41000\n",
    "ylim_time = -4, 4\n",
    "xlim_freq = 0, (2100 / 60) * 2.5\n",
    "ylim_freq = 0, 0.3\n",
    "\n",
    "def get_masked_speed_noise(partcount, T):\n",
    "    \"\"\"\n",
    "    Subtract smoothed speed signal from original speed signal to get the \"noise\"\n",
    "    Further, mask any regions near where the spindle is rapidly accelerating\n",
    "    \"\"\"\n",
    "    speed = get_part_tool(partcount, T)['speed']\n",
    "    if (len(speed) == 0):\n",
    "        return speed\n",
    "    speed_smoothed = speed.rolling(smoothing_window, center=True).mean()\n",
    "    mask = (\n",
    "        (speed_smoothed.diff().abs() > 1)\n",
    "        .rolling(2 * smoothing_window + 1, center=True).sum()\n",
    "        .fillna(1)\n",
    "        .map(bool)\n",
    "    )\n",
    "    return (speed - speed_smoothed).mask(mask)\n",
    "\n",
    "for partcount in test_parts:\n",
    "    if (partcount, test_tool) not in all_parts_tools:\n",
    "        continue\n",
    "    \n",
    "    t_start = time()\n",
    "    speed_noise = get_masked_speed_noise(partcount, test_tool)\n",
    "    freqs, power = periodogram(speed_noise.dropna(), fs=1000)\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(20,10))\n",
    "    \n",
    "    ax = axs[0]\n",
    "    speed_noise.plot(ax=ax, use_index=False, linewidth=0.5)\n",
    "    ax.set_title(f'Part {partcount},  Tool {test_tool}', fontsize=20, fontweight='bold')\n",
    "    ax.set_xlim(xlim_time)\n",
    "    ax.set_ylim(ylim_time)\n",
    "    ax.set_xlabel('Time (milliseconds)')\n",
    "    ax.set_ylabel('Speed noise (RPM)')\n",
    "    \n",
    "    ax = axs[1]\n",
    "    ax.plot(freqs, power, linewidth=1)\n",
    "    ax.set_xlim(xlim_freq)\n",
    "    ax.set_ylim(ylim_freq)\n",
    "    ax.set_xlabel('Frequency (Hz)')\n",
    "    ax.set_ylabel('Power density (arb. units)')\n",
    "    \n",
    "    plt.subplots_adjust(hspace=0.35)\n",
    "    plt.show()\n",
    "    t_elapsed = time() - t_start\n",
    "    sleep(max(0, 0.5 - t_elapsed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Now construct new time series features based on this observation\n",
    "We'll just integrate the spectral power over a handful of frequency bands:\n",
    "* \"low-frequency\": 0 - 100 Hz\n",
    "* \"medium-frequency\": 100 - 250 Hz\n",
    "* \"high-frequency\": 250 - 500 Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feature_rows = []\n",
    "previous_partcount = 0\n",
    "for partcount, T in all_parts_tools:\n",
    "    if partcount != previous_partcount:\n",
    "        print(partcount, end=' ')\n",
    "        previous_partcount = partcount\n",
    "    speed_noise = get_masked_speed_noise(partcount, T)\n",
    "    freqs, power = periodogram(speed_noise.dropna(), fs=1000)\n",
    "    new_feature_rows.append({\n",
    "        'power_low_freq' :power[(  0 <= freqs) & (freqs < 100)].sum(),\n",
    "        'power_med_freq' :power[(100 <= freqs) & (freqs < 250)].sum(),\n",
    "        'power_high_freq':power[(250 <= freqs) & (freqs < 501)].sum(),\n",
    "        })\n",
    "print()\n",
    "\n",
    "df_new_features = pd.DataFrame(index=all_parts_tools, data=new_feature_rows)\n",
    "df_features = df_features.join(df_new_features)\n",
    "\n",
    "plot_feature('power_low_freq')\n",
    "plot_feature('power_med_freq')\n",
    "plot_feature('power_high_freq')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. *Bonus*: Using a spectrogram pinpoints noise anomalies simultaneously in frequency and time\n",
    "What other ways can we think of to apply digital signal processing methods to reveal aspects of impending tool failures?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import spectrogram\n",
    "import numpy as np\n",
    "\n",
    "test_part, test_tool = 100, 1 \n",
    "fig, ax = plt.subplots(figsize=(20,5))\n",
    "speed_noise = get_masked_speed_noise(test_part, test_tool)\n",
    "f, t, power = spectrogram(speed_noise.dropna(), 1000, nfft=2000)\n",
    "heatmap_kwargs = {'cmap':'RdYlBu_r', 'xticklabels':10, 'cbar_kws':{'label': 'arb. units'}}\n",
    "sns.heatmap(\n",
    "    pd.DataFrame(index=f, columns=t, data=np.log(power)).loc[:250].iloc[::-1], \n",
    "    vmin=-20, vmax=-3, **heatmap_kwargs\n",
    ")\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('Frequency (Hz)')\n",
    "plt.title(f'Noise log-spectrogram of a normal part & tool (Part {test_part}, Tool {test_tool})')\n",
    "plt.show()\n",
    "\n",
    "power_ref = power\n",
    "\n",
    "test_part, test_tool = 107, 1 \n",
    "fig, ax = plt.subplots(figsize=(20,5))\n",
    "speed_noise = get_masked_speed_noise(test_part, test_tool)\n",
    "f, t, power = spectrogram(speed_noise.dropna(), 1000, nfft=2000)\n",
    "sns.heatmap(\n",
    "    pd.DataFrame(index=f, columns=t, data=(power - power_ref)).loc[0:250].iloc[::-1], \n",
    "    vmin=-0.03, vmax=0.1, **heatmap_kwargs\n",
    ")\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('Frequency (Hz)')\n",
    "plt.title(f'Noise excess for an early faulty part (Part {test_part}, Tool {test_tool})')\n",
    "plt.show()\n",
    "\n",
    "test_part, test_tool = 121, 1 \n",
    "fig, ax = plt.subplots(figsize=(20,5))\n",
    "speed_noise = get_masked_speed_noise(test_part, test_tool)\n",
    "f, t, power = spectrogram(speed_noise.dropna(), 1000, nfft=2000)\n",
    "sns.heatmap(\n",
    "    pd.DataFrame(index=f, columns=t, data=(power - power_ref)).loc[0:250].iloc[::-1], \n",
    "    vmin=-0.03, vmax=0.1, **heatmap_kwargs\n",
    ")\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('Frequency (Hz)')\n",
    "plt.title(f'Noise excess for a later faulty part (Part {test_part}, Tool {test_tool})')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See our blog post on this topic! https://www.machinemetrics.com/techblog/the-inaugural-machinemetrics-8-track"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
